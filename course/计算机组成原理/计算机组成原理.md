# 计算机组成原理

## 冯诺依曼计算机的设计思想、组成及每部分作用

- `将程序编码，与数据一起放在存储器上面`，计算机就可以直接调用存储器中的数据编码进行操纵数据, 软件和硬件可以直接分离，硬件和软件分开执行，
- 一台计算机由运算器，控制器，存储器，输入和输出设备组成，注意，这里的存储器只是内存，不是外存
- cpu就是运算器和控制器，存储器这里指的是内存，输入输出是键盘，鼠标，显示屏等

- 特点：
  - 数据和指令都放在存储器上，然后都是二进制的形式保存的
  - 顺序执行，执行程序和数据都放在主存储器（内存），执行的时候，按照顺序，从主存储器取出指令，然后一条一条执行
  - 计算机硬件由运算器、控制器、存储器、输入设备和输出设备五大部分组成，这里的存储器主要指的是内存，而不是外存，外存是迫不得已所添加的产物
- 各个部分的作用：
  - 运算器(CPU): 执行存储在存储器中的程序指令，进行算术运算和逻辑运算
  - 存储器：存储程序指令和数据
  - 输入/输出设备：用于与外部环境进行信息交互，接收输入数据和输出计算结果。
  - 控制器：主要用来控制和指挥程序和数据的输入运行，以及处理运算结果。

## 计算机性能指标

- 吞吐量：一台计算机在某一时间间隔内处理的信息量
- 响应时间：从输入到系统响应的时间度量
- 利用率：
- 处理字长：一次运算能够完成二进制运算的位数，32位，64位
- 总线宽度：CPU运算器与存储器之间相互连接的内部总线的二进制位数
- 存储器容量：存储器能存储多少东西，KB,MB,GB,TB
- 存储器贷款：单位时间内存储器读出的二进制数量的信息量
- 主频/时钟周期：就是Hz那个，时钟周期就是$\frac{1}{f}$, f: 主频
- CPU执行时间：CPU执行一般程序所占用的CPU时间
  - $CPU执行时间 = CPU 时钟周期数 \times CPU时钟周期$
  - 其实就是CPU执行一次命令所耗费的时间 乘以 时间 就是CPU执行时间
  - 感觉这样算不是很好的样子
- CPI: 每条指令周期数：即执行一条指令所耗费的平均时钟周期数
  - CPI = $\frac{执行某段CPU时钟周期数}{程序所包含的指令条数}$
- MIPS: 每秒执行多少百万条定点指令数
  - MIPS = $\frac{指令数}{程序执行时间 \times 10^{6}}$
- FLOPS: 每秒执行浮点操作的次数
  - FLOPS = $\frac{程序浮点操作次数}{程序执行时间}$

## 计算机的层次结构

1. 逻辑电路级
2. 微程序的一般机器级
3. 操作系统级
4. 汇编语言级
5. 高级语言级

## 信息的表示和处理

### 进制转换

基本上都是转换成2进制，划分位数将其转换成二进制

- 比如说二进制和十六进制之间转换，将其按照4位4位进行转换
- 二进制和八进制之间转换，按照三位三位进行转换
- 十进制和其他进制之间转换，那么根据权重，辗转相除法进行转换就可以了
  - 整数部分是：除2取整，逆序排列
  - 小数部分：乘2取整，顺序排列

### 原码，反码，补码

- 原码：最高位表示正负，后面表示的是数字
  - eg:
    - 1:  0001,  2:  0010, 3:  0011
    - -1: 1001, -2:  1010, 3:  1011
  - 缺点：
    - 0 有两种表示方法， 0000 和 1000两种方法
    - 负数之间的加减法会出错
- 反码： 正数的反码还是等于原码，负数的反码等于它的原码除了符号位之外，按位数取反
  - eg:
    - 1: 0001, 2: 0010, 3: 0011
    - -1: 1001 -> 1100, -2: 1010 -> 1101, -3: 1011 -> 1100
  - 缺点:
    - 两个负数相加就寄了
- 补码: 计算机中的数据存储都是补码的形式存储的, 可以参考csapp, 进行相关的定义，符号位相当于一个负数的权值
  - eg:
    - 1: 0001, 2: 0010, 3: 0011
    - -1: 1111, -2: 1110, -3: 1101
- 移码：符号位取反的补码
  - 我不知道啊，这玩意有啥用？

### 浮点数的表示

浮点数的表示则采用的是IEEE754(eye triple e)的标准进行编码，因为进制的关系，有些数字是没有办法准确表示的，所以浮点数为了表示一个数字，那么只能近似一个数字来表示一个数字，

- 对于32位浮点数: 1位符号位，8位指数位, 数字位是23位
- 对于64位浮点数: 1位符号位, 指数位11位，数字表示位是52位

- 一个浮点数可以用 $\pm a * 2^{b}$ 的方式进行表示
- 指数因为要表示正数和负数，所以一半来表示正数，一半来表示负数，上面的表示正数，下面的表示负数，所以要减去偏移量，32位是127，64位是1023

这样就可以实现二进制浮点数和十进制之间的转换了

## 存储系统

这里很多都以前学过，csapp等课程已经学过，这里只是简单的陈述一下  
存储器的运行速度过慢（指的是外存），是时代迫不得已妥协的产物，
对于cpu，从高到低分别是：

1. CPU中的寄存器
2. CPU中的cache(有一二三级cache之分，速度依次减少)
3. 内存
4. 外存（硬盘之类的）
5. 网络上的资源（如果说你的速度很快，但是你还要存储到硬盘上，所以上要<= 硬盘的速度，难道不是么（

### DRAM 和 SRAM

- DRAM: dynamic random-access memory 动态随机存储器 主要是寄存器和高速缓存上
- SRAM: static randowm-access memory 静态随机存储器 主要是主存上
- RAM: random access memory 内存
- ROM: read-only memory 只读内存 指的是硬盘

都是一些名词解释，没啥好说的

内存及内存以上的是DRAM, 其他的硬盘之类的是SRAM

### 存储器的性能指标

- 存储容量: 存储的字节数，GB, MB, KB, B
- 存取时间：
- 存储周期
- 存储带宽：单位时间所存取的信息量

### 存储器的优化技术

没搞懂，先空着

### cache

- 这里的`cache`指的是cpu中的一二三缓存，高速缓存中cache会被划分为块的形式进行传递，并且1级的缓存是二级缓存的缓存，就是一级缓存是二级缓存中的一些副本。
- 数据一块的形式在层与层之间进行传递

#### 缓存命中和不命中

- 如果说缓存命中了，那么就直接取出对应的数据
- 如果说缓存不命中，那么就会从更高的缓存中进行fetch, 然后进行替换。这里就有相关的算法了

#### cache三种映射方式

- 直接映射: 将一个主存块存储到唯一的一个cacheline上
- 全相联映射: 可以将主存块存储到任意的一个cacheline上
- 组相联映射：将主存中块存储到一个cache组中的任意一个cacheline上

这里再复习一下

- cache和内存之间的通讯最小单位是64字节，所以说对其到64字节（过的就说了）
- 内存和硬盘的通讯的最小单位是4kb,

#### cache替换策略

LRU算法和LFU算法，这里再algorithm中可以找到

