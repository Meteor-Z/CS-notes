# CMU15445

- 寄存器 = 0.5 sec
- SSD = 1.7 day
- HDD = 16.5 weeks

## File Storage

数据库中的文件在磁盘中是怎么存储的

直接存在磁盘中的文件中，这其中操作系统是不知道的，操作系统只要负责读就行了
数据库是知道在这个文件里面是怎么存储的

## Data Layout

数据在这个数据库系统中的文件是怎么存储的
数据库会将这些数据分页存储 （数据块）
这些 page 可以包含很多东西，如 tuples, meta-data, indexes, log records..
page都有唯一的 id 在 磁盘，同时 page里面的东西存储的一般都是同样的东西

- 硬盘页：(4kb)  磁盘的块，往硬盘里面
- 操作系统的页：(4kb) 存储硬盘的最小单位 人->软件->操作系统->硬盘  linux上的大多数都是4kb
- 数据库的页 :( 512b 到 16kb) MySQL：16kb

## DataBase Heap

将页都串在一起，可以使用链表，或者使用目录的形式存储页，然后页形成了文件

我感觉用目录更好啊，感觉链表贼垃圾

## Page Layout

每一个页里面的
Page里面有一个Header, 和一个Data

header包含：

- Page Size
- Checksum: (md5校验 或者 sha265) 算一个校验码，然后看文件完整性 
- DBMS Version 底层文件有可能在1.0和2.0 不一样，所以有一个校验
- Transaction Visibility，有没有锁qwq
- Compression Information : 压缩信息

研究这个数据是怎么在页里面是怎么存储的

1. 存数据：直接存数据，但是如果删了，那就是有
   1. 在数据里面再存一个索引，然后索引存储在后面的后面，数据虽然是乱的，但是整理之后，也能访问，而且数据是正确的

2. RECORD IDS:数据库内部的概念，

- Tuple Layout

数据怎么存储在这个页里面的数据里面的

Tuple 里面也有一个 Header，数据都存储在后面。直接存储

Slot Array：存储在开头，然后从前往后，数据从后面往前面填充

page中存储的是日志，而不是tuple, 只存储被更新属性的新值，如果要查找数据，那么就要返回找，
`数据库中存储的是log,就是日志，只加载更新的，然后更新的是存储的`

但是这样存储的是非常大，就是修改很多，效率很低，这种数据库会周期性压缩这个数据，

就是比如这样修改
```c++
    int a = 3;
    a++;
    a--;
    a++;
    a++;
    a++;
    a=5;

```
编译器会直接将 a= 5 写入内存，直接进行压缩，优化了代码


## 压缩

按照二叉树那样进行压缩？(块内不能压缩，然后合并直接压缩)
只能压缩7层？

## Tuple Storage

一行数据存储在硬盘里面，二进制是怎么表达的

整数：Intger/BigInt ： 按照C/C++ 那样存储

浮点数： FLOAT,DOUBLE

如果是整数的话，那么就是整数存储，就不会出错

但是如果是浮点数，建议改成字符串进行存储，否贼会出现错误

所以说`Numric`在内存中是这样存储的

```c++
#include <iostream>

typedef unsigned char NumericDigit;

// POSTGRES 的存储
typedef struct
{
    int ndigits; // 数据有多少位
    int weight; // 权重
    int scale;  // 指数，x10 还是 x100
    int sign; // 正数/负数/0
    NumericDigit* digits; // 用字符串来存储 double/float
} numeric;

// Mysql
typedef int32_t decimal_digit_t;
struct decimal_t
{
    int intg, frac, len; // intg: 小数点之前有多少位， frac 是小数点之后多少位， len 是长度
    bool sign; // 正还是负
    decimal_digit_t* buf; // 字面量
};
```

如果说存储的小说超过了页(4kb)的话，那么就用： Overflow Page，（新开一个页，性能是不是寄了？）

什么时候会使用溢出页：
- Postgres: TOAST(2KB)
- Mysql:Overflow(> $\frac{1}{2}$ size of page)
- SQL Server:OverFlow(> sizeo of page)

`注意：建议不要将超大数据全部存储在数据库里面`，放文件，然后存储文件的地址`url`等

## System Catalogs

数据库系统自己记录的数据；

- Tables, columns, indexes, views
- Users, permissions
- Internal statistics

几乎所有的数据库都会将这些信息存储在表中，然后将这些信息自己管理自己

如`Mysql` 就会将这些信息存储在`information-schema`中

```sql
select *
from INFORMATION_SCHEMA.TABLES
where table_catalog = '<db name>'
```

## DataBase WorkLoads

### OLTP

在线事务处理，快速处理，数据量很少
用户在用。

大多数是倾向于写，但是在

### OLAP

在线分析处理，数据量很大
一般都是公司在用

### OLTP + OLAP

混在一起？

### Data WareHouse

数据先在 数据库中传到一个中间部件，然后中间部件存储在 数据仓库

数据放在数据仓库里面，然后在数据仓库里面进行操作

不建议使用外键，直接在应用程序里面进行保证外键的操作

## OBSERVATION

数据在存储的时候不一定是一个`tuple`是一行

如果说要扫`.gov`邮箱的所有的行全部存储起来，但是我不关系其他数据，这时候就不能直接按照行存了，

基本都要`实现`列存，来实现多次实现，然后可以直接分析就坟场好用了。

## 缓存池 (buffer pool)

缓存池中应该怎么实现？



### locks vs latches

locks 是抽象的
latches 是具体的锁眼（手段

- pre_fetching: 读取的时候进行预读取
- scan sharing： 读取的时候会共享数据
- buffer poll bypass: 不进入缓存池
- OS page cache: 操作系统不进行这个缓存

## 哈希表

### Hash 函数

不要使用加密的哈希函数来当作哈希函数

使用`Sha256`加密的话，永远无法逆向的算出原来的东西
所以说不建议使用这个函数来

### 开放地址哈希

如果碰撞的话，那么就往下存，(为什么不使用拉链法)

## 并发

- 自旋锁
- 读锁/写锁

- 锁有先后顺序，并且读锁和写锁是不兼容的，有先后顺序之分
- 局部锁，

- 在`B+`树中，如果是读数据，那么就可以像螃蟹一样，上一个读锁，然后往下走，然后解锁，然后上锁，最后读到数据
- 如果是写数据，如果上锁之后，不能解锁，因为通过修改数据，有可能造成数据结构的形态发生变化，所以上锁的时候就会一直上锁，否则数据会发生改变，直到上面的不会发生改变，那么就会解锁一部分的数据

一个根节点加锁，那么就是悲观锁

如果一个节点不会出现锁根节点，可以在删除数据的时候，可以将读锁换成写锁，这样就会消耗少点 -> 乐观锁

乐观锁：
悲观锁：

如果`B+`树当前返回查找有一定的冲突，那么就有可能发生冲突，两者的锁都在对方的那里，
完蛋，真的会锁住，建议向一个方向进行遍历，查询，修改

## 排序与聚集

缓存池和硬盘进行配合来执行这个数据，因为这个数据太大了

### 排序

普通查询不会排序，因为又可能为了加速，和其他的查询进行合并了

如果将`page1`和`page2`进行排序的话，先将`page1`读入内存，然后排序，之后放在磁盘中，然后进行进行
`page2`，然后再读入到磁盘中，然后将两个`page`进行排序，然后将其读入到磁盘中，
以内磁盘比较大，但是内存比较小，所以这样排序对于磁盘占用小，而且在内存中更快

归并排序在内存和磁盘中来回切换进行读取

预读操作：但是如果不是排序，那么hash就可以直接得到相关数据，比如双Hash,根据算法竞赛比较可以知道，
如果出现错误，其实碰撞几率很低很低

## 连表

- 将小表放在前面？
  - 因为会发生比较，首先在小表中进行筛选，然后又将在第二个表中找到符合条件的值，可以减少不必要的比较次数

### 套嵌循环

这样的时间复杂度基本上等于$O(nm)$了,时间复杂度就会增大

通过优化可以使得这个`IO`磁盘降低，但是还是很低

## 查询优化

### 火山模型

查询的数据会一次次的往上传输数据，也就是向外边吐数据
一个算子中不是一下就直接给上面的，而是一步步的往上传输数据
但是如果是排序的话，那么就不能直接使用这样往上流式传输，而是先缓存住

### XX模型

就是将所有的文件全部吐到上面，这样适合一个单点的文件修改，查询等

### 物化模型

一次吐的时候不是吐一个，而是突出来`一批`数据，

## 执行顺序

从下到上 或者从上到下 来执行这个顺序

## 存储数据

### 顺序遍历

一页一页的扫描，然后传递给上面

## Zone Map

每一页都会做一个统计信息，相当于预处理？

1. 增加了维护成本
2. 如果发生更改，统计信息也会发生改变

## Index Scan

筛选的时候，肯定是筛选的时候筛的越多越好，于是就走这个索引

## 查询顺序

对于 `insert`和`update`，`delete`，这样的操作
你要干很多少事情，比如能不能插入，还有索引什么的

## 万圣节问题

```sql
update people
    set salary = salary + 100
    where salary < 100;
```

在万圣节那天发现了这个问题
这样就有可能会循环更新，所以要记录一下这个数据是不是有没有操作过

## 多线程

## 性能瓶颈

一般都是直接在内存到硬盘之间的`I/O`读取之间的瓶颈

将表切开存储在各个盘中间，然后多线程读取的时候就会增加性能

如果说存入亦或，那么就可以坏了，就可以用好的盘来弄， 好花

你看到的表在硬盘中存储的有可能并不是相同的，因为要提高`IO`性能

## 直方图

个数相同或者桶相同

大表很大，小表小，如果采样，可以在小表中先采样

执行手段还是用左深树和右深树

遗传算法和动态规划算法，如果搜索的表太多了，那么还是考虑遗传算法吧，因为时间复杂度较小，而且最终结果也较好

## 并发控制理论

### 复制文件

将文件备份一遍，然后再跑，如果成功了，那么就覆盖那个旧的，否则，就寄，但是这样显然是错误的

但是这样是不能并发的，复制文件很不好的

多条语句构成的事务要显示告诉数据库这是一个显示的事务，

### ACID

- 原子性 事务是不可以再分的，要么一起执行，要么都不执行 `all or nothing`
- 一致性：执行之后状态是一致的 ？ `it looks correct to me`
- 隔离性：好像再数据库中只有他一个人，跟操作系统跟软件差不多？ `as if alone`
- 持久性：如 `survive failures`,只要提交成功了，就不会丢


### 原子性

- 记录日志，看如果回滚那么应该怎么做？应该将数据设置成什么状态
   - 日志还可以提高性能，然后再空闲的时候再生效

### 一致性

在获取的时候逻辑上应该是正确的

### 隔离性

- 理想上: 只有自己在用这个数据库，理论上最好的数据库
- 但是

如果给数据库一个算法来保证这个顺序在可能错乱的情况下保证数据是对的

## 冲突操作

### 读写冲突 不可重复读

用数据库一个事务的时候应该是相同的。

### 写读冲突 脏读

基于我写入的时候但是我还没有提交的数值去干其他东西 那么就寄了

### 写写冲突 

本来两个事务在一起，如果说正常穿行的话，那么就是留下`T1`或者`T2`的数值，但是如果说是两个都在一起运行，那么最后一个留下的可能是`T1`或者`T2`中的一部分数据

可以通过拓扑排序来解决写读冲突



## 数据库日志

日志文件会在硬盘中存储一份（因为有可能出现`abort！`


### WAL （预写日志）

那不是跟我想的一样（？

先将日志写在硬盘里面，日志里面有很多信息，能够使用`UNDO`和`DO`来进行

内存中会开一个新的空间大小来生成的日志（用来保护日志）

应该先将日志全部存入硬盘里面，但是将日志放入硬盘，就可以保证数据正确

### 日志里面有什么

- Transcaction id (里面包含了时间戳)
- Object Id
- Before Value (UNDO) 可以做多版本并发控制
- After Value (REDO)

如果断电了，根据日志来进行重放，然后将数据全部存入硬盘中

`steal`和`force`之间的使用会在运行和恢复的时候都有不同的区别，

### 检查点 （CheckPoint）

如果说日志很多的话，那么就寄了，因为占用的硬盘很大

在存档里面，所有用户基本都干不了了，

## ARIS

数据库恢复原型算法

提供了基本的理念，很多数据库实现的时候不会是相同的

1. 日志的序列号
2. 正常的提交和回滚的操作
3. 检查点进行优化
4. 恢复算法

### 日志序列号

- flushedLSN
  - 现在有哪一些日志刷到了磁盘中 比如100 ，就是前100已经刷到日志上了
- pageLSN
  - 每一个页都有有一个page,最近修改这个页的修改的日志哪一个（这个日志代表的sql语句修改了这个）
- reclLSN
  - 上一个刷盘之后的第一个版本来计算
- lastLSN
  - 最后一条事务


当前页的数据保存到盘里面话，那么当前数据所在的日志以前的日志也要刷进去
也就是说基于时间戳，都要刷进去

每一条日志还要存储一下上一个日志的地址（对于一个事务来说进行的链表） -> 方便进行回滚，

每次回滚的时候还要再记录一个回滚的日志，

### 检查点优化




## 分布式数据库

普通的数据库都是在放在一个机房里面，然后使用高速局域网来进行连接

分布式数据库每一个节点都来自很多地方，然后很多地方使用公网进行连接

分布式数据库应该公用什么部分？ 比如说这个基于网络然后公用一个硬盘，或者是内存也是公用的？

### SHARED DISK

cpu和内存在一起，然后通过网络访问同一块硬盘，我感觉挺好的

比如说`Oracle`等数据库，

我觉得这个挺好的，硬盘集中化管理，

#### 要解决的问题

但是有可能多个节点要有缓存节点同步，因为有一个节点修改了东西，那么其他节点要同步，知道这个东西

## SHARED NOTHING

CPU和硬盘都是自己的，通过网络来进行通信，那不是直接寄了

那么当前节点没有，那么当前节点需要去其他节点来算出来


### 水平分区

将一个表分开，然后存储在多个不同的硬盘上

